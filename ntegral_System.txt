PartA
Q1:
from sklearn.datasets import load_breast_cancer
data=load_breast_cancer()
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
%matplotlib inline
df=pd.DataFrame(data.data,columns=data.feature_names)
df.head()
X=data.data
y=data.target
from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2)
df['label']=data.target
from sklearn.linear_model import LogisticRegression
md=LogisticRegression()
md.fit(X_train,y_train)
from sklearn.metrics import accuracy_score
y_pred=md.predict(X_test)
accr=accuracy_score(y_pred,y_test)
print("Accuracy is:",accr)
from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay,classification_report
cm=confusion_matrix(y_test,y_pred,labels=md.classes_)
print(cm)
cmd=ConfusionMatrixDisplay(cm)
cmd.plot()
TP,FN,FP,TN=confusion_matrix(y_test,y_pred,labels=md.classes_).ravel()
print(TP,FN,FP,TN)
#find accuracy and other metrics manually
from sklearn.metrics import roc_curve,RocCurveDisplay,auc
fpr,tpr,thresholds=roc_curve(y_test,y_pred)
roc_auc=auc(fpr,tpr)
RocCurveDisplay(fpr=fpr,tpr=tpr,roc_auc=roc_auc).plot()
print(fpr,tpr,roc_auc)

Q2
KNN.py
import numpy as np
from collections import Counter 
def euclidean_distance(x1,x2):
    return np.sqrt(np.sum((x1-x2)**2))
class KNN:
    def __init__(self,k=3):
        self.k=k
    def fit(self,X,y):
        self.X_train=X
        self.y_train=y
    def predict(self,X):
        predictions=[self._predict(x) for x in X]
        return predictions
    def _predict(self,x):
        distances=[euclidean_distance(x,x_train) for x_train in self.X_train]
        k_indices=np.argsort(distances)[:self.k]
        k_nearest_labels=[self.y_train[i] for i in k_indices]
        most_common=Counter(k_nearest_labels).most_common()
        return most_common[0][0]
train.py
import numpy as np
from sklearn import datasets
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
from KNN import KNN
df=datasets.load_iris()
X,y=df.data,df.target
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2)
md=KNN(k=5)
md.fit(X_train,y_train)
pred=md.predict(X_test)
print(pred)
accuracy=np.sum(pred==y_test)/len(y_test)
print(accuracy)

Part B
Q1.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn import linear_model
df=pd.read_csv('Advertising.csv')
df.head()
# print(df.shape)
%matplotlib inline
plt.xlabel('TV Costs')
plt.ylabel('Sales')
plt.scatter(df['TV'],df['sales'])
plt.xlabel('Radio Costs')
plt.ylabel('Sales')
plt.scatter(df['radio'],df['sales'],c='yellow')
plt.xlabel('Newspaper Costs')
plt.ylabel('Sales')
plt.scatter(df['newspaper'],df['sales'],c='green')
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error,mean_absolute_error
def linearReg(x,y):
    x_train,x_test,y_train,y_test=train_test_split(df[x],df[y],test_size=0.2)
    x_train=x_train.to_numpy().reshape(-1,1);
    x_test=x_test.to_numpy().reshape(-1,1);
    y_train=y_train.to_numpy().reshape(-1,1);
    y_test=y_test.to_numpy().reshape(-1,1);
    reg=LinearRegression();
    reg.fit(x_train,y_train)
    regCoeff=reg.coef_[0][0]
    regInter=reg.intercept_[0]
    pred=reg.predict(x_test)
    print("Y="+str(regCoeff)+"X"+"+"+str(regInter));
    plt.scatter(x_train,y_train,c='green')
    plt.scatter(x_test,y_test,c='red')
    plt.plot(x_test,pred,color='yellow')
    mse=mean_squared_error(y_test,pred)
    rootmse=np.sqrt(mse)
    mabe=mean_absolute_error(y_test,pred)
    print("Mean Square Error: "+str(mse)+"Root Mean Square Error: "+str(rootmse)+" Mean Absolute Error: "+str(mabe))
linearReg('TV','sales')
linearReg('newspaper','sales')
linearReg('radio','sales')

Q2.

import pandas as pd
import numpy as np
import seaborn as sns
from sklearn import linear_model
import matplotlib.pyplot as plt
df=pd.read_csv('Advertising.csv')
df.head()
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
x_train,x_test,y_train,y_test=train_test_split(df[['TV','newspaper','radio']],df.sales,test_size=0.3)
reg=LinearRegression()
reg.fit(x_train,y_train)
regCoeff=reg.coef_
regIntercept=reg.intercept_
# print(regCoeff)
print("The Regression Line is: Y= "+str(regCoeff[0])+"*TV + "+str(regCoeff[1])+"*newspaper + "+str(regCoeff[2])+"*radio")
from sklearn.metrics import mean_squared_error,mean_absolute_error
y_pred=reg.predict(x_test)
mse=mean_squared_error(y_test,y_pred)
rmse=np.sqrt(mse)
mae=mean_absolute_error(y_test,y_pred)
score=reg.score(x_train,y_train)
print("Mean Squared Error is: "+str(mse)+" Mean Absolute Error is: "+str(mae)+" Score is: "+str(score))
sns.pairplot(df,x_vars=['TV','radio','newspaper'],y_vars=['sales'],kind='reg',height=5)

Q3.

import pandas as pd
df=pd.read_csv('titanic.csv')
df.head()
df.drop(['Name','Siblings/Spouses Aboard','Parents/Children Aboard'],axis=1,inplace=True)
df.head()
df.Age=df.Age.fillna(df.Age.mean())
df.head()
from sklearn.preprocessing import LabelEncoder,StandardScaler
encoder=LabelEncoder()
df['Sex']=encoder.fit_transform(df['Sex'])
scaler=StandardScaler()
df[['Age','Fare']]=scaler.fit_transform(df[['Age','Fare']])
df.head()
from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(df[['Pclass','Sex','Age','Fare']],df['Survived'],test_size=0.2)
from sklearn.naive_bayes import GaussianNB
md=GaussianNB()
md.fit(x_train,y_train)
y_pred=md.predict(x_test)
from sklearn.metrics import confusion_matrix,accuracy_score,f1_score,ConfusionMatrixDisplay
accr=accuracy_score(y_pred,y_test)
f1_sc=f1_score(y_pred,y_test)
print("Accuracy: "+str(accr)+"\nF1-Score: "+str(f1_sc))
cm=confusion_matrix(y_test,y_pred)
cmd=ConfusionMatrixDisplay(cm)
cmd.plot()

Q4.

import pandas as pd
import matplotlib.pyplot as plt
df=pd.read_csv('Iris.csv')
df.head()
from sklearn.naive_bayes import MultinomialNB
from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(df[['SepalLengthCm','SepalWidthCm','PetalWidthCm']],df.Species,test_size=0.3)
md=MultinomialNB()
md.fit(x_train,y_train)
from sklearn.metrics import accuracy_score,confusion_matrix,precision_score,recall_score,ConfusionMatrixDisplay
y_pred=md.predict(x_test)
acc=accuracy_score(y_test,y_pred)
prec=precision_score(y_test,y_pred,average='micro')
rec=recall_score(y_test,y_pred,average='micro')
print("Accuracy is: ",acc,"Precision is: ",prec," Recall is: ",rec)
cm=confusion_matrix(y_test,y_pred)
cmd=ConfusionMatrixDisplay(cm)
cmd.plot()
